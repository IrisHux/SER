{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "032a6b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ad571a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Path: D:/Unitec/SER\\dataset\\IEMOCAP\n",
      "Evaluation Dataset Path: D:/Unitec/SER\\dataset\\CREMA-D\n",
      "IEMOCAP Preprocessed Dir: D:/Unitec/SER\\dataset\\IEMOCAP\\Preprocessed\n",
      "CREMA-D Preprocessed Dir: D:/Unitec/SER\\dataset\\CREMA-D\\Preprocessed\n",
      "IEMOCAP Emotions: ['ang', 'neu', 'sad', 'hap']\n",
      "CREMA-D Emotions: ['ang', 'neu', 'sad', 'hap']\n"
     ]
    }
   ],
   "source": [
    "from core.config import CONFIG\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    CONFIG.load_config(\"config.yaml\")\n",
    "\n",
    "    print(\"Training Dataset Path:\", CONFIG.dataset_path(\"training\"))\n",
    "    print(\"Evaluation Dataset Path:\", CONFIG.dataset_path(\"evaluation\"))\n",
    "    print(\"IEMOCAP Preprocessed Dir:\", CONFIG.dataset_preprocessed_dir_path(CONFIG.training_dataset_name()))\n",
    "    print(\"CREMA-D Preprocessed Dir:\", CONFIG.dataset_preprocessed_dir_path(CONFIG.evaluation_dataset_name()))\n",
    "    print(\"IEMOCAP Emotions:\", CONFIG.dataset_emotions(CONFIG.training_dataset_name()))\n",
    "    print(\"CREMA-D Emotions:\", CONFIG.dataset_emotions(CONFIG.evaluation_dataset_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad4e5e1",
   "metadata": {},
   "source": [
    "## test processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96b6db8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Target emotions being extracted: ['ang', 'neu', 'sad', 'hap']\n",
      "\n",
      "[INFO] Preprocessing complete. Total entries extracted: 4490\n",
      "[INFO] Emotion distribution:\n",
      "emotion\n",
      "neu    1708\n",
      "ang    1103\n",
      "sad    1084\n",
      "hap     595\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[INFO] Data per session:\n",
      "session\n",
      "Session3    1000\n",
      "Session1     942\n",
      "Session5     942\n",
      "Session2     813\n",
      "Session4     793\n",
      "Name: count, dtype: int64\n",
      "DataFrame head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_path</th>\n",
       "      <th>audio_filename</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:/Unitec/SER\\dataset\\IEMOCAP\\Session1\\sentenc...</td>\n",
       "      <td>Ses01F_impro01_F000.wav</td>\n",
       "      <td>Excuse me.</td>\n",
       "      <td>neu</td>\n",
       "      <td>Session1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:/Unitec/SER\\dataset\\IEMOCAP\\Session1\\sentenc...</td>\n",
       "      <td>Ses01F_impro01_F001.wav</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>neu</td>\n",
       "      <td>Session1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:/Unitec/SER\\dataset\\IEMOCAP\\Session1\\sentenc...</td>\n",
       "      <td>Ses01F_impro01_F002.wav</td>\n",
       "      <td>Is there a problem?</td>\n",
       "      <td>neu</td>\n",
       "      <td>Session1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:/Unitec/SER\\dataset\\IEMOCAP\\Session1\\sentenc...</td>\n",
       "      <td>Ses01F_impro01_F005.wav</td>\n",
       "      <td>Well what's the problem?  Let me change it.</td>\n",
       "      <td>neu</td>\n",
       "      <td>Session1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:/Unitec/SER\\dataset\\IEMOCAP\\Session1\\sentenc...</td>\n",
       "      <td>Ses01F_impro01_F012.wav</td>\n",
       "      <td>That's out of control.</td>\n",
       "      <td>ang</td>\n",
       "      <td>Session1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          audio_path           audio_filename  \\\n",
       "0  D:/Unitec/SER\\dataset\\IEMOCAP\\Session1\\sentenc...  Ses01F_impro01_F000.wav   \n",
       "1  D:/Unitec/SER\\dataset\\IEMOCAP\\Session1\\sentenc...  Ses01F_impro01_F001.wav   \n",
       "2  D:/Unitec/SER\\dataset\\IEMOCAP\\Session1\\sentenc...  Ses01F_impro01_F002.wav   \n",
       "3  D:/Unitec/SER\\dataset\\IEMOCAP\\Session1\\sentenc...  Ses01F_impro01_F005.wav   \n",
       "4  D:/Unitec/SER\\dataset\\IEMOCAP\\Session1\\sentenc...  Ses01F_impro01_F012.wav   \n",
       "\n",
       "                                          text emotion   session  \n",
       "0                                   Excuse me.     neu  Session1  \n",
       "1                                        Yeah.     neu  Session1  \n",
       "2                          Is there a problem?     neu  Session1  \n",
       "3  Well what's the problem?  Let me change it.     neu  Session1  \n",
       "4                       That's out of control.     ang  Session1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4490 entries, 0 to 4489\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   audio_path      4490 non-null   object\n",
      " 1   audio_filename  4490 non-null   object\n",
      " 2   text            4490 non-null   object\n",
      " 3   emotion         4490 non-null   object\n",
      " 4   session         4490 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 175.5+ KB\n",
      "\n",
      "Emotion Distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "neu    1708\n",
       "ang    1103\n",
       "sad    1084\n",
       "hap     595\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data per Session:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "session\n",
       "Session3    1000\n",
       "Session1     942\n",
       "Session5     942\n",
       "Session2     813\n",
       "Session4     793\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from core.config import CONFIG\n",
    "from preprocessing.iemocap import IemocapPreprocessor\n",
    "\n",
    "# 确保 CONFIG 已经加载了配置文件\n",
    "CONFIG.load_config(\"config.yaml\")\n",
    "\n",
    "# 初始化 IemocapPreprocessor，使用配置中训练数据集的路径\n",
    "# 假设您想验证训练数据的加载\n",
    "iemocap_dataset_path = CONFIG.dataset_path(\"training\")\n",
    "iemocap_preprocessor = IemocapPreprocessor(iemocap_dataset_path)\n",
    "\n",
    "# 生成 DataFrame\n",
    "iemocap_df = iemocap_preprocessor.generate_dataframe()\n",
    "\n",
    "# 显示 DataFrame 的前几行\n",
    "print(\"DataFrame head:\")\n",
    "display(iemocap_df.head())\n",
    "\n",
    "# 您还可以打印一些关于 DataFrame 的信息来进一步验证\n",
    "print(\"\\nDataFrame Info:\")\n",
    "iemocap_df.info()\n",
    "\n",
    "print(\"\\nEmotion Distribution:\")\n",
    "display(iemocap_df['emotion'].value_counts())\n",
    "\n",
    "print(\"\\nData per Session:\")\n",
    "display(iemocap_df['session'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "823ad63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Target emotions being extracted for CREMA-D: ['ang', 'neu', 'sad', 'hap']\n",
      "\n",
      "[INFO] CREMA-D Preprocessing complete. Total entries extracted: 4900\n",
      "[INFO] Emotion distribution for CREMA-D:\n",
      "emotion\n",
      "ang    1271\n",
      "hap    1271\n",
      "sad    1271\n",
      "neu    1087\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[INFO] Data per Speaker:\n",
      "speaker\n",
      "1001    54\n",
      "1003    54\n",
      "1004    54\n",
      "1011    54\n",
      "1005    54\n",
      "        ..\n",
      "1002    53\n",
      "1076    53\n",
      "1019    50\n",
      "1009    50\n",
      "1008    50\n",
      "Name: count, Length: 91, dtype: int64\n",
      "DataFrame head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_path</th>\n",
       "      <th>audio_filename</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:/Unitec/SER\\dataset\\CREMA-D\\AudioWAV\\1001_DF...</td>\n",
       "      <td>1001_DFA_ANG_XX.wav</td>\n",
       "      <td>Don't forget a jacket</td>\n",
       "      <td>ang</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:/Unitec/SER\\dataset\\CREMA-D\\AudioWAV\\1001_DF...</td>\n",
       "      <td>1001_DFA_HAP_XX.wav</td>\n",
       "      <td>Don't forget a jacket</td>\n",
       "      <td>hap</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:/Unitec/SER\\dataset\\CREMA-D\\AudioWAV\\1001_DF...</td>\n",
       "      <td>1001_DFA_NEU_XX.wav</td>\n",
       "      <td>Don't forget a jacket</td>\n",
       "      <td>neu</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:/Unitec/SER\\dataset\\CREMA-D\\AudioWAV\\1001_DF...</td>\n",
       "      <td>1001_DFA_SAD_XX.wav</td>\n",
       "      <td>Don't forget a jacket</td>\n",
       "      <td>sad</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:/Unitec/SER\\dataset\\CREMA-D\\AudioWAV\\1001_IE...</td>\n",
       "      <td>1001_IEO_ANG_HI.wav</td>\n",
       "      <td>It's eleven o'clock</td>\n",
       "      <td>ang</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          audio_path       audio_filename  \\\n",
       "0  D:/Unitec/SER\\dataset\\CREMA-D\\AudioWAV\\1001_DF...  1001_DFA_ANG_XX.wav   \n",
       "1  D:/Unitec/SER\\dataset\\CREMA-D\\AudioWAV\\1001_DF...  1001_DFA_HAP_XX.wav   \n",
       "2  D:/Unitec/SER\\dataset\\CREMA-D\\AudioWAV\\1001_DF...  1001_DFA_NEU_XX.wav   \n",
       "3  D:/Unitec/SER\\dataset\\CREMA-D\\AudioWAV\\1001_DF...  1001_DFA_SAD_XX.wav   \n",
       "4  D:/Unitec/SER\\dataset\\CREMA-D\\AudioWAV\\1001_IE...  1001_IEO_ANG_HI.wav   \n",
       "\n",
       "                    text emotion speaker  \n",
       "0  Don't forget a jacket     ang    1001  \n",
       "1  Don't forget a jacket     hap    1001  \n",
       "2  Don't forget a jacket     neu    1001  \n",
       "3  Don't forget a jacket     sad    1001  \n",
       "4    It's eleven o'clock     ang    1001  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4900 entries, 0 to 4899\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   audio_path      4900 non-null   object\n",
      " 1   audio_filename  4900 non-null   object\n",
      " 2   text            4900 non-null   object\n",
      " 3   emotion         4900 non-null   object\n",
      " 4   speaker         4900 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 191.5+ KB\n",
      "\n",
      "Emotion Distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "ang    1271\n",
       "hap    1271\n",
       "sad    1271\n",
       "neu    1087\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data per speaker:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "speaker\n",
       "1001    54\n",
       "1003    54\n",
       "1004    54\n",
       "1011    54\n",
       "1005    54\n",
       "        ..\n",
       "1002    53\n",
       "1076    53\n",
       "1019    50\n",
       "1009    50\n",
       "1008    50\n",
       "Name: count, Length: 91, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from preprocessing.cremad import CremaDPreprocessor\n",
    "\n",
    "# 假设您想验证训练数据的加载\n",
    "cremad_dataset_path = CONFIG.dataset_path(\"evaluation\")\n",
    "cremad_preprocessor = CremaDPreprocessor(cremad_dataset_path)\n",
    "\n",
    "# 生成 DataFrame\n",
    "cremad_df = cremad_preprocessor.generate_dataframe()\n",
    "\n",
    "# 显示 DataFrame 的前几行\n",
    "print(\"DataFrame head:\")\n",
    "display(cremad_df.head())\n",
    "\n",
    "# 您还可以打印一些关于 DataFrame 的信息来进一步验证\n",
    "print(\"\\nDataFrame Info:\")\n",
    "cremad_df.info()\n",
    "\n",
    "print(\"\\nEmotion Distribution:\")\n",
    "display(cremad_df['emotion'].value_counts())\n",
    "\n",
    "print(\"\\nData per speaker:\")\n",
    "display(cremad_df['speaker'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2879db",
   "metadata": {},
   "source": [
    "### lenth of wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a49da01",
   "metadata": {},
   "source": [
    "我需要先查看这个函数是否有任何错误提示或者运行时的错误信息。让我检查一下错误详情。 \n",
    "\n",
    "Checked [](file:///d%3A/Unitec/SER/test_tools.ipynb), no problems found\n",
    "\n",
    "让我运行这个代码块来看看是否有运行时错误： \n",
    "\n",
    "Ran [](vscode-notebook-cell:/d%3A/Unitec/SER/test_tools.ipynb#W6sZmlsZQ%3D%3D)\n",
    "\n",
    "现在我看到错误了！问题是在 `print_waveform_lengths` 函数中，当没有成功处理任何音频文件时，`waveform_lengths` 列表为空，导致创建的 `lengths_df` DataFrame 也是空的，因此没有 `'length_seconds'` 列。\n",
    "\n",
    "让我检查一下 `iemocap_df` 和 `cremad_df` 是否已经定义： \n",
    "\n",
    "Ran [](vscode-notebook-cell:/d%3A/Unitec/SER/test_tools.ipynb#W3sZmlsZQ%3D%3D)\n",
    "\n",
    "Ran [](vscode-notebook-cell:/d%3A/Unitec/SER/test_tools.ipynb#W4sZmlsZQ%3D%3D)\n",
    "\n",
    "现在我知道问题所在了。数据框架是存在的，但是 `print_waveform_lengths` 函数在尝试加载音频文件时遇到了错误，导致 `waveform_lengths` 列表为空。让我修复这个函数，添加更好的错误处理： \n",
    "\n",
    "Editing notebook\n",
    "\n",
    "现在让我再次运行这个代码块来看看具体的错误： \n",
    "\n",
    "Ran [](vscode-notebook-cell:/d%3A/Unitec/SER/test_tools.ipynb#W6sZmlsZQ%3D%3D)\n",
    "\n",
    "让我检查输出： \n",
    "\n",
    "Read output of [](vscode-notebook-cell:/d%3A/Unitec/SER/test_tools.ipynb#W6sZmlsZQ%3D%3D)\n",
    "\n",
    "现在我明白问题了！错误是 `torchaudio` 找不到合适的后端来处理音频文件。这通常意味着需要安装额外的音频处理库。让我们检查一下音频文件是否存在，并尝试使用不同的方法： \n",
    "\n",
    "Ran terminal command: ls \"D:\\Unitec\\SER\\dataset\\IEMOCAP\\Session1\\sentences\\wav\\Ses01F_impro01\\Ses01F_impro01_F000.wav\" 2>$null; if ($?) { echo \"File exists\" } else { echo \"File not found\" }\n",
    "\n",
    "文件是存在的。问题是 `torchaudio` 需要额外的音频后端库来处理 WAV 文件。让我们安装所需的库： \n",
    "\n",
    "Installing packages librosa, soundfile in Python 3.12.3 (.venv)\n",
    "Completed with input: {\n",
    "  \"packageList\": [\n",
    "    \"soundfile\",\n",
    "    \"librosa\"\n",
    "  ],\n",
    "  \"resourcePath\": \"d:\\\\Unitec\\\\SER\"\n",
    "}\n",
    "\n",
    "现在让我修改代码，明确指定使用 soundfile 作为后端，或者使用 librosa 作为备选方案： \n",
    "\n",
    "Editing notebook\n",
    "\n",
    "现在让我们重新运行代码： \n",
    "\n",
    "Ran [](vscode-notebook-cell:/d%3A/Unitec/SER/test_tools.ipynb#W6sZmlsZQ%3D%3D)\n",
    "\n",
    "让我检查输出结果： \n",
    "\n",
    "Read output of [](vscode-notebook-cell:/d%3A/Unitec/SER/test_tools.ipynb#W6sZmlsZQ%3D%3D)\n",
    "\n",
    "看起来 `torchaudio.set_audio_backend(\"soundfile\")` 没有起作用。让我们重启内核并尝试另一种方法，使用 `librosa` 来加载音频文件： \n",
    "\n",
    "Editing notebook\n",
    "\n",
    "现在让我们重新运行修正后的代码： \n",
    "\n",
    "Ran [](vscode-notebook-cell:/d%3A/Unitec/SER/test_tools.ipynb#W6sZmlsZQ%3D%3D)\n",
    "\n",
    "太好了！现在代码工作正常了。让我总结一下之前遇到的错误和解决方案：\n",
    "\n",
    "#### 错误分析与解决方案\n",
    "\n",
    "**原始错误：**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dca31de",
   "metadata": {
    "vscode": {
     "languageId": ""
    }
   },
   "outputs": [],
   "source": [
    "KeyError: 'length_seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaceac3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**根本原因：**\n",
    "1. `torchaudio` 无法找到合适的音频后端来处理 WAV 文件\n",
    "2. 导致所有音频文件加载失败，`waveform_lengths` 列表为空\n",
    "3. 空列表创建的 DataFrame 没有 `'length_seconds'` 列，引发 KeyError\n",
    "\n",
    "**解决方案：**\n",
    "1. **安装必要的音频处理库：** 安装了 `soundfile` 和 `librosa`\n",
    "2. **更换音频加载库：** 从 `torchaudio` 改为使用 `librosa.load()`\n",
    "3. **增强错误处理：** 添加了更好的错误检查和处理逻辑\n",
    "\n",
    "**最终结果：**\n",
    "- IEMOCAP 数据集：4490 个文件，平均长度 4.50 秒，最长 31.91 秒\n",
    "- CREMA-D 数据集：4900 个文件，平均长度 2.49 秒，最长 5.01 秒\n",
    "- 所有文件的采样率都是 16kHz\n",
    "\n",
    "这个错误提醒我们在处理音频数据时，确保有适当的音频处理库和后端支持是很重要的。\n",
    "\n",
    "Made changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0744871b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with first 5 files from each dataset:\n",
      "IEMOCAP sample:\n",
      "IEMOCAP (sample) Waveform Lengths:\n",
      "\n",
      "Successfully processed 5 files\n",
      "\n",
      "Summary Statistics (in seconds):\n",
      "count    5.000000\n",
      "mean     2.647638\n",
      "std      1.030508\n",
      "min      1.382437\n",
      "25%      1.945563\n",
      "50%      2.750000\n",
      "75%      3.130250\n",
      "max      4.029937\n",
      "Name: length_seconds, dtype: float64\n",
      "\n",
      "Sample rate statistics:\n",
      "sample_rate\n",
      "16000    5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "CREMA-D sample:\n",
      "CREMA-D (sample) Waveform Lengths:\n",
      "\n",
      "Successfully processed 5 files\n",
      "\n",
      "Summary Statistics (in seconds):\n",
      "count    5.000000\n",
      "mean     2.023338\n",
      "std      0.154880\n",
      "min      1.868500\n",
      "25%      1.935250\n",
      "50%      2.002000\n",
      "75%      2.035375\n",
      "max      2.275562\n",
      "Name: length_seconds, dtype: float64\n",
      "\n",
      "Sample rate statistics:\n",
      "sample_rate\n",
      "16000    5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "\n",
      "Processing full datasets:\n",
      "IEMOCAP Waveform Lengths:\n",
      "\n",
      "Successfully processed 4490 files\n",
      "\n",
      "Summary Statistics (in seconds):\n",
      "count    4490.000000\n",
      "mean        4.495215\n",
      "std         3.171135\n",
      "min         0.730000\n",
      "25%         2.321250\n",
      "50%         3.509937\n",
      "75%         5.699937\n",
      "max        31.910000\n",
      "Name: length_seconds, dtype: float64\n",
      "\n",
      "Sample rate statistics:\n",
      "sample_rate\n",
      "16000    4490\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------\n",
      "\n",
      "CREMA-D Waveform Lengths:\n",
      "\n",
      "Successfully processed 4900 files\n",
      "\n",
      "Summary Statistics (in seconds):\n",
      "count    4900.000000\n",
      "mean        2.489760\n",
      "std         0.478087\n",
      "min         1.334688\n",
      "25%         2.168813\n",
      "50%         2.435750\n",
      "75%         2.769437\n",
      "max         5.005000\n",
      "Name: length_seconds, dtype: float64\n",
      "\n",
      "Sample rate statistics:\n",
      "sample_rate\n",
      "16000    4900\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the length of each waveform in the dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "def print_waveform_lengths(df, dataset_name):\n",
    "    print(f\"{dataset_name} Waveform Lengths:\")\n",
    "    waveform_lengths = []\n",
    "\n",
    "    # Use apply to get the length of each waveform\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            # Check if file exists first\n",
    "            if not os.path.exists(row['audio_path']):\n",
    "                print(f\"Warning: File not found: {row['audio_path']}\")\n",
    "                continue\n",
    "                \n",
    "            # Load the audio file using librosa instead of torchaudio\n",
    "            waveform, sample_rate = librosa.load(row['audio_path'], sr=None)\n",
    "            length_in_samples = len(waveform)\n",
    "            length_in_seconds = length_in_samples / sample_rate\n",
    "            waveform_lengths.append({\n",
    "                'index': idx, \n",
    "                'length_samples': length_in_samples, \n",
    "                'length_seconds': length_in_seconds,\n",
    "                'sample_rate': sample_rate,\n",
    "                'audio_path': row['audio_path']\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {row['audio_path']}: {e}\")\n",
    "\n",
    "    # Check if we have any successful measurements\n",
    "    if not waveform_lengths:\n",
    "        print(f\"Warning: No audio files could be processed for {dataset_name}\")\n",
    "        return None\n",
    "\n",
    "    # Convert to DataFrame for better visualization\n",
    "    lengths_df = pd.DataFrame(waveform_lengths)\n",
    "\n",
    "    # Display summary statistics\n",
    "    print(f\"\\nSuccessfully processed {len(lengths_df)} files\")\n",
    "    print(\"\\nSummary Statistics (in seconds):\")\n",
    "    print(lengths_df['length_seconds'].describe())\n",
    "    \n",
    "    print(\"\\nSample rate statistics:\")\n",
    "    print(lengths_df['sample_rate'].value_counts())\n",
    "    \n",
    "    return lengths_df\n",
    "\n",
    "# Test with a smaller sample first to debug\n",
    "print(\"Testing with first 5 files from each dataset:\")\n",
    "print(\"IEMOCAP sample:\")\n",
    "iemocap_sample_result = print_waveform_lengths(iemocap_df.head(5), \"IEMOCAP (sample)\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 40 + \"\\n\")\n",
    "\n",
    "print(\"CREMA-D sample:\")\n",
    "cremad_sample_result = print_waveform_lengths(cremad_df.head(5), \"CREMA-D (sample)\")\n",
    "\n",
    "# If samples work, process full datasets\n",
    "if iemocap_sample_result is not None and cremad_sample_result is not None:\n",
    "    print(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "    print(\"Processing full datasets:\")\n",
    "    \n",
    "    iemocap_full_result = print_waveform_lengths(iemocap_df, \"IEMOCAP\")\n",
    "    print(\"\\n\"+\"-\" * 20 + \"\\n\")\n",
    "    cremad_full_result = print_waveform_lengths(cremad_df, \"CREMA-D\")\n",
    "else:\n",
    "    print(\"\\nSkipping full dataset processing due to errors in sample files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f4541d",
   "metadata": {},
   "source": [
    "### tokenizer of text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3520ea",
   "metadata": {},
   "source": [
    "def analyze_text_lengths(dataset_name, df):\n",
    "    print(f\"\\n--- {dataset_name} 文本长度分析 ---\")\n",
    "含义：定义一个分析函数，传入数据集名字和含有文本列的 DataFrame。\n",
    "\n",
    "目的：分数据集输出统计摘要，便于横向对比（比如 IEMOCAP vs CREMA-D）。\n",
    "\n",
    "设计思考：多数据集循环复用时，打印标题更清晰。\n",
    "\n",
    "python\n",
    "复制代码\n",
    "    # 计算token长度\n",
    "    token_lengths = []\n",
    "    for text in df['text']:\n",
    "        tokens = tokenizer(text, padding=False, truncation=False)\n",
    "        token_lengths.append(len(tokens['input_ids']))\n",
    "含义：对每一条文本调用 HuggingFace 的 tokenizer，取 input_ids 长度。\n",
    "\n",
    "原理：\n",
    "\n",
    "tokenizer 会做子词分词（BPE / WordPiece / SentencePiece），把句子拆成 token 并映射到 id。\n",
    "\n",
    "默认 add_special_tokens=True，因此单句会被包上 [CLS] / [SEP]（BERT/DeBERTa）或 <s> / </s>（RoBERTa）等特殊符号。\n",
    "\n",
    "padding=False：不补齐，得到真实长度；truncation=False：不截断，保留尾部，便于看极值/百分位。\n",
    "\n",
    "理论依据：\n",
    "\n",
    "Transformer 的时间/显存复杂度 ~ O(L²)（多头自注意力），L 越大成本越高；\n",
    "\n",
    "设定 max_length=L_text 需要知道数据真实分布，以避开不必要的 padding 和减少截断带来的信息损失。\n",
    "\n",
    "设计思考：\n",
    "\n",
    "计数时包含特殊符号是对的，因为训练/推理时真实长度就包含它们；\n",
    "\n",
    "如果你想分析“纯内容 token”长度，可再做一版 add_special_tokens=False 的统计（下方我给改进版）。\n",
    "\n",
    "python\n",
    "复制代码\n",
    "    # 转为 Series 便于分析\n",
    "    lengths_series = pd.Series(token_lengths)\n",
    "含义：用 pandas 便于做统计、画图、导出。\n",
    "\n",
    "目的：后续 describe、分组统计、保存报告都很方便。\n",
    "\n",
    "python\n",
    "复制代码\n",
    "    # 显示统计摘要\n",
    "    print(\"Token长度统计:\")\n",
    "    stats = lengths_series.describe(percentiles=[.5, .75, .9, .95, .99])\n",
    "    print(stats)\n",
    "含义：输出计数、均值、标准差、min/max、以及 50/75/90/95/99 分位点。\n",
    "\n",
    "目的：\n",
    "\n",
    "P95/P99 是选 L_text 的关键参考：\n",
    "\n",
    "若 P95 = 62，多半可以把 L_text 设为 64；\n",
    "\n",
    "若 P99 = 123，则设 128 保险；\n",
    "\n",
    "也能看尾部是不是长尾严重（决定是否做长文本策略：滑窗、截断规则等）。\n",
    "\n",
    "理论依据：\n",
    "\n",
    "长度分布—资源权衡：把 L_text 设在 P95 附近通常能显著省内存，且仅截断极少数样本；\n",
    "\n",
    "如果任务对完整性很敏感（如问答），可设在 P99；SER 转写通常较短，P95 足够。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9f7733e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- IEMOCAP 文本长度分析 ---\n",
      "Token长度统计:\n",
      "count    4490.000000\n",
      "mean       17.435857\n",
      "std        12.742214\n",
      "min         3.000000\n",
      "50%        14.000000\n",
      "75%        23.000000\n",
      "90%        34.000000\n",
      "95%        43.000000\n",
      "99%        61.000000\n",
      "max       115.000000\n",
      "dtype: float64\n",
      "\n",
      "分位数分布:\n",
      "50% 的样本 token 长度 <= 14\n",
      "75% 的样本 token 长度 <= 23\n",
      "90% 的样本 token 长度 <= 34\n",
      "95% 的样本 token 长度 <= 43\n",
      "99% 的样本 token 长度 <= 61\n",
      "\n",
      "--- CREMA-D 文本长度分析 ---\n",
      "Token长度统计:\n",
      "count    4900.000000\n",
      "mean        8.774898\n",
      "std         1.546893\n",
      "min         6.000000\n",
      "50%         9.000000\n",
      "75%        10.000000\n",
      "90%        11.000000\n",
      "95%        11.000000\n",
      "99%        11.000000\n",
      "max        11.000000\n",
      "dtype: float64\n",
      "\n",
      "分位数分布:\n",
      "50% 的样本 token 长度 <= 9\n",
      "75% 的样本 token 长度 <= 10\n",
      "90% 的样本 token 长度 <= 11\n",
      "95% 的样本 token 长度 <= 11\n",
      "99% 的样本 token 长度 <= 11\n",
      "\n",
      "--- 综合分析 ---\n",
      "95% 分位数: 34\n",
      "99% 分位数: 54\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer\n",
    "from core.config import CONFIG\n",
    "\n",
    "# 加载配置\n",
    "CONFIG.load_config(\"config.yaml\")\n",
    "\n",
    "# 使用与模型相匹配的分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(CONFIG.text_encoder_name())\n",
    "\n",
    "# 分析数据集的文本长度\n",
    "def analyze_text_lengths(dataset_name, df):\n",
    "    print(f\"\\n--- {dataset_name} 文本长度分析 ---\")\n",
    "    \n",
    "    # 计算token长度\n",
    "    token_lengths = []\n",
    "    for text in df['text']:\n",
    "        tokens = tokenizer(text, padding=False, truncation=False)\n",
    "        token_lengths.append(len(tokens['input_ids']))\n",
    "    \n",
    "    # 转为 Series 便于分析\n",
    "    lengths_series = pd.Series(token_lengths)\n",
    "    \n",
    "    # 显示统计摘要\n",
    "    print(\"Token长度统计:\")\n",
    "    stats = lengths_series.describe(percentiles=[.5, .75, .9, .95, .99])\n",
    "    print(stats)\n",
    "    \n",
    "    # 显示分位数\n",
    "    print(\"\\n分位数分布:\")\n",
    "    for p in [50, 75, 90, 95, 99]:\n",
    "        print(f\"{p}% 的样本 token 长度 <= {np.percentile(token_lengths, p):.0f}\")\n",
    "    \n",
    "    # 绘制直方图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(token_lengths, bins=30, alpha=0.7)\n",
    "    plt.axvline(np.percentile(token_lengths, 95), color='r', linestyle='--', \n",
    "                label=f'95%分位数: {np.percentile(token_lengths, 95):.0f}')\n",
    "    plt.title(f'{dataset_name} 文本 Token 长度分布')\n",
    "    plt.xlabel('Token 长度')\n",
    "    plt.ylabel('样本数量')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    return token_lengths\n",
    "\n",
    "# 分析 IEMOCAP 数据集\n",
    "iemocap_token_lengths = analyze_text_lengths(\"IEMOCAP\", iemocap_df)\n",
    "\n",
    "# 分析 CREMA-D 数据集\n",
    "cremad_token_lengths = analyze_text_lengths(\"CREMA-D\", cremad_df)\n",
    "\n",
    "# 整合两个数据集的统计结果，找到合适的截断点\n",
    "all_lengths = iemocap_token_lengths + cremad_token_lengths\n",
    "print(\"\\n--- 综合分析 ---\")\n",
    "print(f\"95% 分位数: {np.percentile(all_lengths, 95):.0f}\")\n",
    "print(f\"99% 分位数: {np.percentile(all_lengths, 99):.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab5c8c4",
   "metadata": {},
   "source": [
    "## 实例化数据集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65b09ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Unitec\\SER\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载 IEMOCAP 数据集用于训练...\n",
      "--- 正在为数据集 'IEMOCAP' 准备Dataloaders (实时处理模式) ---\n",
      "[INFO] 已从以下路径加载原始数据信息: E:/Unitec/SER/dataset\\IEMOCAP\\Preprocessed\\iemocap_raw.pkl\n",
      "[INFO] 使用的 processor 类型: <class 'transformers.models.wav2vec2.feature_extraction_wav2vec2.Wav2Vec2FeatureExtractor'>\n"
     ]
    }
   ],
   "source": [
    "from core.config import CONFIG\n",
    "from scripts.get_dataloaders import get_dataloaders\n",
    "CONFIG.load_config(\"config.yaml\")\n",
    "\n",
    "# --- 训练和验证流程 ---\n",
    "print(\"加载 IEMOCAP 数据集用于训练...\")\n",
    "# 只需一行代码，即可获取训练和验证所需的所有 dataloader\n",
    "iemocap_loaders = get_dataloaders(CONFIG.training_dataset_name())\n",
    "train_loader = iemocap_loaders['train']\n",
    "validation_loader = iemocap_loaders['validation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd0b9d",
   "metadata": {},
   "source": [
    "### train baseline model（New）\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a66ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 正在加载 'IEMOCAP' 数据集用于训练和验证 ---\n",
      "--- 正在为数据集 'IEMOCAP' 准备Dataloaders ---\n",
      "[INFO] 使用内存优化模式\n",
      "[INFO] 已从以下路径加载音频特征: E:/Iris_project/SER\\dataset\\IEMOCAP\\Preprocessed\\iemocap_audio_features.pkl\n",
      "[INFO] 已从以下路径加载文本Tokens: E:/Iris_project/SER\\dataset\\IEMOCAP\\Preprocessed\\iemocap_text_tokens.pkl\n",
      "[INFO] 使用内存优化的数据整理器\n",
      "[INFO] 已清理加载过程中的临时内存\n",
      "\n",
      "--- 正在加载 'CREMA-D' 数据集用于零样本评估 ---\n",
      "--- 正在为数据集 'CREMA-D' 准备Dataloaders ---\n",
      "[INFO] 使用内存优化模式\n",
      "[INFO] 已从以下路径加载音频特征: E:/Iris_project/SER\\dataset\\CREMA-D\\Preprocessed\\crema-d_audio_features.pkl\n",
      "[INFO] 已从以下路径加载文本Tokens: E:/Iris_project/SER\\dataset\\CREMA-D\\Preprocessed\\crema-d_text_tokens.pkl\n",
      "[INFO] 使用内存优化的数据整理器\n",
      "[INFO] 已清理加载过程中的临时内存\n",
      "\n",
      "--- 初始化基线模型和训练器 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of WavLMForSequenceClassification were not initialized from the model checkpoint at microsoft/wavlm-base and are newly initialized: ['projector.bias', 'projector.weight', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1158: UserWarning: expandable_segments not supported on this platform (Triggered internally at ..\\c10\\cuda\\CUDACachingAllocator.cpp:803.)\n",
      "  return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\wavlm\\modeling_wavlm.py:1434: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5. Please use the equivalent `freeze_feature_encoder` method instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 特征提取层已冻结，使用梯度累积步数: 8\n",
      "\n",
      "--- 开始在 IEMOCAP 上训练基线模型 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/449 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Rerun the training cell\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "from core.config import CONFIG, device\n",
    "from scripts.get_dataloaders import get_dataloaders\n",
    "from audio.baseline_model import AudioBaselineModel\n",
    "from audio.trainer import MemoryOptimizedAudioBaselineTrainer\n",
    "\n",
    "# 设置CUDA内存优化\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "CONFIG.load_config(\"config.yaml\")\n",
    "\n",
    "# --- 训练和验证流程 ---\n",
    "training_dataset_name = CONFIG.training_dataset_name()\n",
    "print(f\"\\n--- 正在加载 '{training_dataset_name}' 数据集用于训练和验证 ---\")\n",
    "\n",
    "# 使用内存优化版本的dataloaders（这是主要的改动）\n",
    "try:\n",
    "    # 使用内存优化版本\n",
    "    iemocap_loaders = get_dataloaders(training_dataset_name, use_memory_optimization=True)\n",
    "    train_loader = iemocap_loaders['train']\n",
    "    validation_loader = iemocap_loaders['validation']\n",
    "    \n",
    "    # --- 零样本评估流程 (在 CREMA-D 上) ---\n",
    "    evaluation_dataset_name = CONFIG.evaluation_dataset_name()\n",
    "    print(f\"\\n--- 正在加载 '{evaluation_dataset_name}' 数据集用于零样本评估 ---\")\n",
    "    \n",
    "    cremad_loaders = get_dataloaders(evaluation_dataset_name, use_memory_optimization=True)\n",
    "    evaluation_loader = cremad_loaders['evaluation']\n",
    "    \n",
    "    # --- 实例化模型和训练器 ---\n",
    "    print(\"\\n--- 初始化基线模型和训练器 ---\")\n",
    "    \n",
    "    # 清理内存后创建模型\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    # 获取情感标签\n",
    "    iemocap_emotions = CONFIG.dataset_emotions(training_dataset_name)\n",
    "    num_labels = len(iemocap_emotions)\n",
    "    \n",
    "    # 创建模型（考虑使用更小的batch_size)\n",
    "    baseline_model = AudioBaselineModel(num_labels=num_labels).to(device)\n",
    "    \n",
    "    # 使用内存优化版本的训练器\n",
    "    baseline_trainer = MemoryOptimizedAudioBaselineTrainer(  # 使用新的训练器\n",
    "        model=baseline_model,\n",
    "        num_epochs=CONFIG.training_epochs(),\n",
    "        learning_rate=CONFIG.learning_rate() * 4,  # 由于梯度累积，需要调整学习率\n",
    "        optimizer_type=CONFIG.optimizer_type(),\n",
    "        gradient_accumulation_steps=8  # 梯度累积步数，可以根据需要调整\n",
    "    )\n",
    "    \n",
    "    # --- 步骤 3: 训练模型 ---\n",
    "    print(\"\\n--- 开始在 IEMOCAP 上训练基线模型 ---\")\n",
    "    baseline_trainer.train(train_loader)\n",
    "    \n",
    "    # --- 步骤 4: 在 IEMOCAP 验证集上评估 ---\n",
    "    print(\"\\n--- 在 IEMOCAP 验证集上评估模型性能 ---\")\n",
    "    baseline_trainer.eval(validation_loader, labels=iemocap_emotions)\n",
    "    \n",
    "    # --- 步骤 5: 在 CREMA-D 测试集上进行零样本评估 ---\n",
    "    print(\"\\n--- 在 CREMA-D 测试集上进行零样本评估 ---\")\n",
    "    cremad_emotions = CONFIG.dataset_emotions(evaluation_dataset_name)\n",
    "    baseline_trainer.eval(evaluation_loader, labels=cremad_emotions)\n",
    "    \n",
    "    print(\"\\n--- 基线模型训练和评估完成！ ---\")\n",
    "\n",
    "except torch.cuda.OutOfMemoryError as e:\n",
    "    print(f\"\\n[ERROR] CUDA内存不足: {e}\")\n",
    "    print(\"建议:\")\n",
    "    print(\"1. 进一步减小batch_size到1\")\n",
    "    print(\"2. 减少音频最大长度\")\n",
    "    print(\"3. 使用更小的模型variant\")\n",
    "    print(\"4. 重启运行时清理内存\")\n",
    "    \n",
    "    # 清理内存\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n[ERROR] 训练过程中出现错误: {e}\")\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37be2ef",
   "metadata": {},
   "source": [
    "### check cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "697ad0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Check PyTorch and CUDA ---\n",
      "Python Version: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]\n",
      "PyTorch Version: 2.1.2+cu121\n",
      "Is CUDA available: True\n",
      "\n",
      "--- 2. Get GPU Device Information ---\n",
      "Default CUDA device: cuda:0\n",
      "GPU Name: NVIDIA L40S-6Q\n",
      "PyTorch compiled with CUDA version: 12.1\n",
      "\n",
      "--- 3. Test Data Transfer Between CPU and GPU ---\n",
      "a. Tensor created on the CPU: tensor([1, 2, 3])\n",
      "   - Device: cpu\n",
      "\n",
      "[ERROR] Failed to move data to GPU: CUDA error: operation not supported\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "print(\"--- 1. Check PyTorch and CUDA ---\")\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "# Check if CUDA is available\n",
    "is_cuda_available = torch.cuda.is_available()\n",
    "print(f\"Is CUDA available: {is_cuda_available}\")\n",
    "\n",
    "if not is_cuda_available:\n",
    "    print(\"\\n[ERROR] PyTorch could not detect CUDA. Please check your NVIDIA driver and PyTorch installation.\")\n",
    "    # If CUDA is not available, exit the script\n",
    "    sys.exit()\n",
    "\n",
    "print(\"\\n--- 2. Get GPU Device Information ---\")\n",
    "# Get the default CUDA device (usually GPU 0)\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(f\"Default CUDA device: {device}\")\n",
    "\n",
    "# Print the name of the GPU\n",
    "gpu_name = torch.cuda.get_device_name(0)\n",
    "print(f\"GPU Name: {gpu_name}\")\n",
    "\n",
    "# Print the CUDA version PyTorch was compiled with\n",
    "torch_cuda_version = torch.version.cuda\n",
    "print(f\"PyTorch compiled with CUDA version: {torch_cuda_version}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- 3. Test Data Transfer Between CPU and GPU ---\")\n",
    "# a. Create a tensor on the CPU\n",
    "cpu_tensor = torch.tensor([1, 2, 3], device='cpu')\n",
    "print(f\"a. Tensor created on the CPU: {cpu_tensor}\")\n",
    "print(f\"   - Device: {cpu_tensor.device}\")\n",
    "\n",
    "# b. Try to move the tensor to the GPU\n",
    "try:\n",
    "    gpu_tensor = cpu_tensor.to(device)\n",
    "    print(f\"\\nb. Successfully moved tensor to GPU: {gpu_tensor}\")\n",
    "    print(f\"   - Device: {gpu_tensor.device}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n[ERROR] Failed to move data to GPU: {e}\")\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "print(\"\\n--- 4. Test Computation on GPU ---\")\n",
    "# a. Create two tensors on the GPU for computation\n",
    "try:\n",
    "    a = torch.randn(3, 3).to(device)\n",
    "    b = torch.randn(3, 3).to(device)\n",
    "    print(f\"a. Created two 3x3 random tensors on the GPU.\")\n",
    "    print(f\"   - Tensor a device: {a.device}\")\n",
    "    print(f\"   - Tensor b device: {b.device}\")\n",
    "\n",
    "    # b. Perform matrix multiplication on the GPU\n",
    "    print(\"\\nb. Performing matrix multiplication on GPU (c = a * b)...\")\n",
    "    c = torch.matmul(a, b)\n",
    "    print(f\"   - Result c device: {c.device}\")\n",
    "    print(f\"   - Computation successful!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n[ERROR] Computation on GPU failed: {e}\")\n",
    "    sys.exit()\n",
    "\n",
    "print(\"\\n--- 5. Test Moving Result Back to CPU ---\")\n",
    "# a. Move the computation result from GPU back to CPU\n",
    "try:\n",
    "    result_cpu_tensor = c.cpu()\n",
    "    print(\"a. Successfully moved the computation result back to the CPU.\")\n",
    "    print(f\"   - Device: {result_cpu_tensor.device}\")\n",
    "    print(\"\\nComputation result:\")\n",
    "    print(result_cpu_tensor)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n[ERROR] Failed to move result back to CPU: {e}\")\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "print(\"\\n--- All tests completed ---\")\n",
    "print(\"[SUCCESS] Your PyTorch and CUDA environment is configured correctly, and they can communicate and perform computations normally!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ce7a1f",
   "metadata": {},
   "source": [
    "### （pass）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fa1a8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: operation not supported\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscripts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mget_dataloaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_dataloaders\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maudio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbaseline_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AudioBaselineModel\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maudio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AudioBaselineTrainer\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m      8\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m    主函数，用于执行声学基线模型的完整训练和评估流程。\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Iris_project\\SER\\audio\\trainer.py:16\u001b[39m\n\u001b[32m     13\u001b[39m torch.set_float32_matmul_precision(\u001b[33m\"\u001b[39m\u001b[33mhigh\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# 可选：首次预热，避免第一次调用卡顿\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m _ = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# class AudioTrainer(AbstractTrainer):\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m#     def __init__(\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m#         self,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     44\u001b[39m \n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# 假设 AbstractTrainer 已经从 core/trainer.py 导入或在notebook中定义\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: operation not supported\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from core.config import CONFIG, device\n",
    "from scripts.get_dataloaders import get_dataloaders\n",
    "from audio.baseline_model import AudioBaselineModel\n",
    "from audio.trainer import AudioBaselineTrainer\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    主函数，用于执行声学基线模型的完整训练和评估流程。\n",
    "    \"\"\"\n",
    "    # 1. 加载配置文件\n",
    "    CONFIG.load_config(\"config.yaml\")\n",
    "    print(f\"--- 实验配置已加载 ---\")\n",
    "    print(f\"使用的设备: {device}\")\n",
    "\n",
    "    # --- 训练和验证流程 ---\n",
    "    training_dataset_name = CONFIG.training_dataset_name()\n",
    "    print(f\"\\n--- 正在加载 '{training_dataset_name}' 数据集用于训练和验证 ---\")\n",
    "    \n",
    "    # 使用高级函数获取训练和验证所需的所有 dataloader\n",
    "    iemocap_loaders = get_dataloaders(training_dataset_name)\n",
    "    train_loader = iemocap_loaders['train']\n",
    "    validation_loader = iemocap_loaders['validation']\n",
    "\n",
    "    # 3. 初始化模型\n",
    "    # 从配置中获取情感标签列表，以确定模型的输出维度\n",
    "    num_labels = len(CONFIG.dataset_emotions(training_dataset_name))\n",
    "    print(f\"\\n--- 正在初始化 AudioBaselineModel (类别数: {num_labels}) ---\")\n",
    "    model = AudioBaselineModel(num_labels=num_labels).to(device)\n",
    "\n",
    "    # 4. 初始化训练器\n",
    "    print(f\"--- 正在初始化 AudioBaselineTrainer ---\")\n",
    "    trainer = AudioBaselineTrainer(\n",
    "        model=model,\n",
    "        num_epochs=CONFIG.training_epochs(),\n",
    "        learning_rate=CONFIG.learning_rate(),\n",
    "        optimizer_type=CONFIG.optimizer_type()\n",
    "    )\n",
    "\n",
    "    # 5. 开始训练\n",
    "    trainer.train(train_loader)\n",
    "\n",
    "    # 6. 在验证集上评估\n",
    "    print(f\"\\n--- 正在 '{training_dataset_name}' 的验证集上进行评估 ---\")\n",
    "    trainer.eval(validation_loader, labels=CONFIG.dataset_emotions(training_dataset_name))\n",
    "\n",
    "    # --- 零样本评估流程 (在 CREMA-D 上) ---\n",
    "    evaluation_dataset_name = CONFIG.evaluation_dataset_name()\n",
    "    print(f\"\\n--- 正在加载 '{evaluation_dataset_name}' 数据集用于零样本评估 ---\")\n",
    "    \n",
    "    cremad_loaders = get_dataloaders(evaluation_dataset_name)\n",
    "    evaluation_loader = cremad_loaders['evaluation']\n",
    "    \n",
    "    print(f\"\\n--- 正在 '{evaluation_dataset_name}' 上进行零样本评估 ---\")\n",
    "    trainer.eval(evaluation_loader, labels=CONFIG.dataset_emotions(evaluation_dataset_name))\n",
    "    \n",
    "    print(\"\\n--- 训练和评估流程全部完成 ---\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d06293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "已创建训练集，包含 3592 个样本。\n",
      "已创建验证集，包含 898 个样本。\n",
      "已创建训练集，包含 3920 个样本。\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 第 1 步: 加载必要的库和你的自定义类 ---\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import Wav2Vec2FeatureExtractor, DebertaV2Tokenizer\n",
    "import os\n",
    "\n",
    "from dataloaders.dataset import CustomSERDataset\n",
    "from scripts.get_dataloaders import CustomDataCollator\n",
    "\n",
    "\n",
    "# --- 确定计算设备 ---\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- 第 2 步: 初始化处理器和分词器 ---\n",
    "# 这些是collator需要的 \"工具\"\n",
    "audio_processor = Wav2Vec2FeatureExtractor.from_pretrained(CONFIG.audio_encoder_name())\n",
    "text_tokenizer = DebertaV2Tokenizer.from_pretrained(CONFIG.text_encoder_name())\n",
    "\n",
    "# --- 第 3 步: 实例化训练数据集 (IEMOCAP) ---\n",
    "# 注意：你需要先运行你的预处理脚本，生成统一的元数据文件\n",
    "\n",
    "\n",
    "# 定义最大长度 (例如10秒)\n",
    "MAX_LEN_IN_SECONDS = 10\n",
    "max_audio_len = 16000 * MAX_LEN_IN_SECONDS\n",
    "\n",
    "iemocap_emotions = CONFIG.dataset_emotions(CONFIG.training_dataset_name())\n",
    "train_dataset = CustomSERDataset(\n",
    "    metadata_file_path=os.path.join(CONFIG.dataset_preprocessed_dir_path(CONFIG.training_dataset_name()),iemocap_metadata_filename), # 使用配置和生成的文件名\n",
    "    emotions=iemocap_emotions,\n",
    "    target_sample_rate=audio_processor.sampling_rate,\n",
    "    split='train',\n",
    "    max_audio_length=max_audio_len # 传入参数\n",
    ")\n",
    "\n",
    "# 创建IEMOCAP验证数据集\n",
    "val_dataset = CustomSERDataset(\n",
    "    metadata_file_path=os.path.join(CONFIG.dataset_preprocessed_dir_path(CONFIG.training_dataset_name()),iemocap_metadata_filename),\n",
    "    emotions=iemocap_emotions,\n",
    "    target_sample_rate=audio_processor.sampling_rate,\n",
    "    split='val',\n",
    "    max_audio_length=max_audio_len # 传入参数\n",
    ")\n",
    "\n",
    "# --- 第 4 步: 实例化评估数据集 (CREMA-D) ---\n",
    "cremad_emotions = CONFIG.dataset_emotions(CONFIG.evaluation_dataset_name())\n",
    "eval_dataset = CustomSERDataset(\n",
    "    metadata_file_path=os.path.join(CONFIG.dataset_preprocessed_dir_path(CONFIG.evaluation_dataset_name()),cremad_metadata_filename), # 使用配置和生成的文件名\n",
    "    emotions=cremad_emotions,\n",
    "    target_sample_rate=audio_processor.sampling_rate,\n",
    "    max_audio_length=max_audio_len # 传入参数\n",
    ")\n",
    "\n",
    "\n",
    "# --- 第 5 步: 实例化你的数据整理器 ---\n",
    "# 数据整理器对于训练集和评估集是通用的\n",
    "data_collator = CustomDataCollator(\n",
    "    audio_processor=audio_processor,\n",
    "    text_tokenizer=text_tokenizer,\n",
    "    # device=device # device 来自你的CONFIG或Notebook顶部定义\n",
    ")\n",
    "\n",
    "# --- 第 6 步: 创建训练集的 DataLoader ---\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG.dataloader_dict()['batch_size'],\n",
    "    shuffle=True, # 训练集通常需要打乱\n",
    "    collate_fn=data_collator, # 关键！在这里传入你的自定义整理器\n",
    "    # num_workers=CONFIG.dataloader_dict()['num_workers'],\n",
    "    # pin_memory=True\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=CONFIG.dataloader_dict()['batch_size'], \n",
    "    shuffle=False, \n",
    "    collate_fn=data_collator, \n",
    "    # num_workers=CONFIG.dataloader_dict()['num_workers'], \n",
    "    # pin_memory=True\n",
    ")\n",
    "\n",
    "# --- 验证batch size ---\n",
    "print(train_dataloader.batch_size)\n",
    "\n",
    "# --- 第 7 步: 创建评估集的 DataLoader ---\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_dataset,\n",
    "    batch_size=CONFIG.dataloader_dict()['batch_size'],\n",
    "    shuffle=False, # 评估集通常不需要打乱\n",
    "    collate_fn=data_collator, # 关键！在这里传入你的自定义整理器\n",
    "    # num_workers=CONFIG.dataloader_dict()['num_workers'],\n",
    "    # pin_memory=True\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbf763c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 验证 DataLoader 和 Collator (详细调试模式) ---\n",
      "\n",
      "验证训练集 DataLoader:\n",
      "成功从 DataLoader 获取 CPU 批次。\n",
      "\n",
      "开始逐个将张量移动到 GPU...\n",
      "准备移动 'audio_input_values'... | 类型: torch.float32 | 形状: torch.Size([1, 32, 160000])\n",
      "'audio_input_values' 移动成功！\n",
      "准备移动 'text_input_ids'... | 类型: torch.int64 | 形状: torch.Size([32, 54])\n",
      "'text_input_ids' 移动成功！\n",
      "准备移动 'text_attention_mask'... | 类型: torch.int64 | 形状: torch.Size([32, 54])\n",
      "'text_attention_mask' 移动成功！\n",
      "准备移动 'labels'... | 类型: torch.int64 | 形状: torch.Size([32])\n",
      "'labels' 移动成功！\n",
      "\n",
      "所有张量均已成功移动到 GPU！\n",
      "--- 验证 DataLoader 和 Collator ---\n",
      "\n",
      "验证训练集 DataLoader:\n",
      "成功从训练集 DataLoader 获取一个批次！\n",
      "批次包含的键: dict_keys(['audio_input_values', 'text_input_ids', 'text_attention_mask', 'labels'])\n",
      "音频输入形状: torch.Size([1, 32, 160000])\n",
      "文本输入形状: torch.Size([32, 53])\n",
      "标签形状: torch.Size([32])\n",
      "\n",
      "验证评估集 DataLoader:\n",
      "成功从评估集 DataLoader 获取一个批次！\n",
      "批次包含的键: dict_keys(['audio_input_values', 'text_input_ids', 'text_attention_mask', 'labels'])\n",
      "音频输入形状: torch.Size([1, 32, 160000])\n",
      "文本输入形状: torch.Size([32, 11])\n",
      "标签形状: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# --- 第 8 步 (验证): 精确定位问题的详细调试 ---\n",
    "print(\"--- 验证 DataLoader 和 Collator (详细调试模式) ---\")\n",
    "print(\"\\n验证训练集 DataLoader:\")\n",
    "\n",
    "# 初始化一个空的 gpu_batch 字典\n",
    "gpu_batch = {}\n",
    "try:\n",
    "    # 1. 获取 CPU 批次 (这一步已经成功)\n",
    "    cpu_batch = next(iter(train_dataloader))\n",
    "    print(\"成功从 DataLoader 获取 CPU 批次。\")\n",
    "\n",
    "    # 2. 逐个检查并移动张量\n",
    "    print(\"\\n开始逐个将张量移动到 GPU...\")\n",
    "\n",
    "    # 检查 'audio_input_values'\n",
    "    key = 'audio_input_values'\n",
    "    tensor = cpu_batch[key]\n",
    "    print(f\"准备移动 '{key}'... | 类型: {tensor.dtype} | 形状: {tensor.shape}\")\n",
    "    gpu_batch[key] = tensor.to(device)\n",
    "    print(f\"'{key}' 移动成功！\")\n",
    "\n",
    "    # 检查 'text_input_ids'\n",
    "    key = 'text_input_ids'\n",
    "    tensor = cpu_batch[key]\n",
    "    print(f\"准备移动 '{key}'... | 类型: {tensor.dtype} | 形状: {tensor.shape}\")\n",
    "    gpu_batch[key] = tensor.to(device)\n",
    "    print(f\"'{key}' 移动成功！\")\n",
    "\n",
    "    # 检查 'text_attention_mask'\n",
    "    key = 'text_attention_mask'\n",
    "    tensor = cpu_batch[key]\n",
    "    print(f\"准备移动 '{key}'... | 类型: {tensor.dtype} | 形状: {tensor.shape}\")\n",
    "    gpu_batch[key] = tensor.to(device)\n",
    "    print(f\"'{key}' 移动成功！\")\n",
    "\n",
    "    # 检查 'labels'\n",
    "    key = 'labels'\n",
    "    tensor = cpu_batch[key]\n",
    "    print(f\"准备移动 '{key}'... | 类型: {tensor.dtype} | 形状: {tensor.shape}\")\n",
    "    gpu_batch[key] = tensor.to(device)\n",
    "    print(f\"'{key}' 移动成功！\")\n",
    "\n",
    "    print(\"\\n所有张量均已成功移动到 GPU！\")\n",
    "\n",
    "except Exception as e:\n",
    "    # 如果出错，我们会明确知道是在处理哪个 key 时发生的\n",
    "    print(f\"\\n在尝试移动 '{key}' 张量时出错: {e}\")\n",
    "\n",
    "# --- 第 8 步 (验证): 从DataLoader中取出一个批次，检查其内容 ---\n",
    "print(\"--- 验证 DataLoader 和 Collator ---\")\n",
    "print(\"\\n验证训练集 DataLoader:\")\n",
    "try:\n",
    "    first_train_batch = next(iter(train_dataloader))\n",
    "    print(\"成功从训练集 DataLoader 获取一个批次！\")\n",
    "    print(\"批次包含的键:\", first_train_batch.keys())\n",
    "    print(\"音频输入形状:\", first_train_batch['audio_input_values'].shape)\n",
    "    print(\"文本输入形状:\", first_train_batch['text_input_ids'].shape)\n",
    "    print(\"标签形状:\", first_train_batch['labels'].shape)\n",
    "except Exception as e:\n",
    "    print(f\"获取训练集批次时出错: {e}\")\n",
    "\n",
    "print(\"\\n验证评估集 DataLoader:\")\n",
    "try:\n",
    "    first_eval_batch = next(iter(eval_dataloader))\n",
    "    print(\"成功从评估集 DataLoader 获取一个批次！\")\n",
    "    print(\"批次包含的键:\", first_eval_batch.keys())\n",
    "    print(\"音频输入形状:\", first_eval_batch['audio_input_values'].shape)\n",
    "    print(\"文本输入形状:\", first_eval_batch['text_input_ids'].shape)\n",
    "    print(\"标签形状:\", first_eval_batch['labels'].shape)\n",
    "except Exception as e:\n",
    "    print(f\"获取评估集批次时出错: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bde94d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 初始化基线模型和训练器 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of WavLMForSequenceClassification were not initialized from the model checkpoint at microsoft/wavlm-base-plus and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'classifier.weight', 'projector.bias', 'projector.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 正在冻结WavLM的特征提取层...\n",
      "[INFO] 特征提取层已冻结。\n",
      "\n",
      "--- 开始在 IEMOCAP 上训练基线模型 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  34%|███▎      | 38/113 [2:23:33<4:43:21, 226.68s/it, accuracy=0.406, loss=1.3]  \n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 94.00 MiB. GPU 0 has a total capacty of 6.00 GiB of which 0 bytes is free. Of the allocated memory 17.57 GiB is allocated by PyTorch, and 968.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# --- 步骤 3: 训练模型 ---\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- 开始在 IEMOCAP 上训练基线模型 ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43mbaseline_trainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# --- 步骤 4: 在 IEMOCAP 验证集上评估 ---\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- 在 IEMOCAP 验证集上评估模型性能 ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Iris_project\\SER\\core\\trainer.py:57\u001b[39m, in \u001b[36mAbstractTrainer.train\u001b[39m\u001b[34m(self, train_dataloader)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Backward\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m torch.nn.utils.clip_grad_norm_(\u001b[38;5;28mself\u001b[39m.model.parameters(), \u001b[32m1.0\u001b[39m)\n\u001b[32m     59\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    482\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    483\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    484\u001b[39m         Tensor.backward,\n\u001b[32m    485\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    490\u001b[39m         inputs=inputs,\n\u001b[32m    491\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    246\u001b[39m     retain_graph = create_graph\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 94.00 MiB. GPU 0 has a total capacty of 6.00 GiB of which 0 bytes is free. Of the allocated memory 17.57 GiB is allocated by PyTorch, and 968.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from audio.baseline_model import AudioBaselineModel\n",
    "from audio.trainer import AudioBaselineTrainer\n",
    "# 实例化模型和训练器 ---\n",
    "print(\"\\n--- 初始化基线模型和训练器 ---\")\n",
    "num_labels = len(iemocap_emotions)\n",
    "baseline_model = AudioBaselineModel(num_labels=num_labels).to(device)\n",
    "\n",
    "baseline_trainer = AudioBaselineTrainer(\n",
    "    model=baseline_model,\n",
    "    num_epochs=CONFIG.training_epochs(),\n",
    "    learning_rate=CONFIG.learning_rate(),\n",
    "    optimizer_type=CONFIG.optimizer_type()\n",
    ")\n",
    "\n",
    "# --- 步骤 3: 训练模型 ---\n",
    "print(\"\\n--- 开始在 IEMOCAP 上训练基线模型 ---\")\n",
    "baseline_trainer.train(train_dataloader)\n",
    "\n",
    "# --- 步骤 4: 在 IEMOCAP 验证集上评估 ---\n",
    "print(\"\\n--- 在 IEMOCAP 验证集上评估模型性能 ---\")\n",
    "baseline_trainer.eval(val_dataloader, labels=iemocap_emotions)\n",
    "\n",
    "# --- 步骤 5: 在 CREMA-D 测试集上进行零样本评估 ---\n",
    "print(\"\\n--- 在 CREMA-D 测试集上进行零样本评估 ---\")\n",
    "baseline_trainer.eval(eval_dataloader, labels=cremad_emotions)\n",
    "\n",
    "print(\"\\n--- 基线模型训练和评估完成！ ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
