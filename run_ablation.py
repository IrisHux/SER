# run_ablation.py

"""
ç»Ÿä¸€çš„æ¶ˆèå®éªŒè¿è¡Œè„šæœ¬ï¼ˆè®­ç»ƒ + è¯„ä¼°ï¼‰
æ”¯æŒè¿è¡Œä¸¤ç§æ¶ˆèå®éªŒï¼š
1. Ablation A: LGCA w/o Label-Guidance (æ— æ ‡ç­¾ç›‘ç£)
2. Ablation B: LGCA w/o Text Anchor (æ— æ–‡æœ¬é”šç‚¹)

ç±»ä¼¼äº run_contrastive.py çš„ç»“æ„ï¼Œä½†ç”¨äºæ¶ˆèå®éªŒ
"""

import torch
import gc
import os
import logging
import numpy as np
import random
import warnings
import argparse
from pathlib import Path

# å¯¼å…¥é¡¹ç›®æ ¸å¿ƒæ¨¡å—
from core.config import CONFIG, device
from contrastive.model import setup_memory_optimization, MemoryOptimizedContrastiveModel, AcousticSupConModel
from contrastive.trainer import AblationNoLabelTrainer, AblationNoTextTrainer
from scripts.get_dataloaders import get_contrastive_dataloaders, get_ablation_no_text_dataloaders
from scripts.contrastive_ops import ModelOps  # ä½¿ç”¨é€šç”¨å·¥å…·ç±»
from vizualisers.plots import PlotVisualizer  # ä¿®å¤ï¼šå¯¼å…¥ PlotVisualizer ç±»

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def prepare_environment():
    """å‡†å¤‡å®éªŒç¯å¢ƒï¼šåŠ è½½é…ç½®ã€è®¾ç½®éšæœºç§å­ã€ä¼˜åŒ–å†…å­˜"""
    warnings.filterwarnings("ignore", category=UserWarning)
    warnings.filterwarnings("ignore", category=FutureWarning)
    
    # 1. åŠ è½½é…ç½®
    try:
        CONFIG.load_config("config.yaml")
        logger.info("é…ç½®æ–‡ä»¶ 'config.yaml' åŠ è½½æˆåŠŸã€‚")
    except FileNotFoundError:
        logger.error("é”™è¯¯ï¼šæ‰¾ä¸åˆ° 'config.yaml' æ–‡ä»¶ã€‚")
        raise
    
    # 2. è®¾ç½®éšæœºç§å­
    seed = 42
    torch.manual_seed(seed)
    np.random.seed(seed)
    random.seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
    
    # 3. å†…å­˜ä¼˜åŒ–
    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
    setup_memory_optimization()
    torch.cuda.empty_cache()
    gc.collect()
    
    logger.info("ç¯å¢ƒå‡†å¤‡å®Œæˆã€‚")


def run_ablation_no_label(run_training: bool = True, run_evaluation: bool = True, alpha: float = None):
    """
    è¿è¡Œæ¶ˆèå®éªŒ A: LGCA w/o Label-Guidance (è®­ç»ƒ + è¯„ä¼°)
    
    Args:
        run_training: æ˜¯å¦è¿è¡Œè®­ç»ƒ
        run_evaluation: æ˜¯å¦è¿è¡Œè¯„ä¼°
        alpha: æŸå¤±æƒé‡ç³»æ•° (å¦‚æœä¸º Noneï¼Œåˆ™ä» config.yaml è¯»å–)
    """
    logger.info("\n" + "="*80)
    logger.info("æ¶ˆèå®éªŒ A: LGCA w/o Label-Guidance")
    logger.info("="*80)
    
    # ä» config è·å– alpha å€¼
    if alpha is None:
        alpha = CONFIG.llgca_loss_alpha()
        logger.info(f"ä»é…ç½®æ–‡ä»¶è¯»å– alpha = {alpha}")
    
    training_dataset_name = CONFIG.training_dataset_name()
    evaluation_dataset_name = CONFIG.evaluation_dataset_name()
    num_labels = len(CONFIG.dataset_emotions(training_dataset_name))
    
    # === é˜¶æ®µ 1: è®­ç»ƒ ===
    if run_training:
        logger.info("\n==================== [é˜¶æ®µ 1: å¼€å§‹è®­ç»ƒ] ====================")
        
        # 1. åˆ›å»ºæ¨¡å‹ï¼ˆä½¿ç”¨ ModelOpsï¼‰
        model = ModelOps.create_or_load_model(
            model_class=MemoryOptimizedContrastiveModel,
            num_labels=num_labels
        )
        
        # 2. åˆ›å»ºè®­ç»ƒå™¨ï¼ˆä½¿ç”¨ ModelOpsï¼‰
        trainer = ModelOps.create_trainer(
            trainer_class=AblationNoLabelTrainer,
            model=model,
            alpha=alpha
        )
        
        # 3. è¿è¡Œè®­ç»ƒï¼ˆä½¿ç”¨ ModelOpsï¼‰
        ModelOps.train(
            trainer=trainer,
            training_dataset_name=training_dataset_name,
            dataloader_func=get_contrastive_dataloaders
        )
        
        # 4. è®­ç»ƒåç«‹å³åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
        logger.info("--- å¯¹è®­ç»ƒå®Œæˆçš„æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šè¿›è¡Œè¯„ä¼° ---")
        ModelOps.evaluate(
            trainer=trainer,
            dataset_split='validation',
            dataset_name=training_dataset_name,
            dataloader_func=get_contrastive_dataloaders
        )
        
        logger.info("==================== [é˜¶æ®µ 1: è®­ç»ƒå®Œæˆ] ====================\n")
        
        # æ¸…ç†å†…å­˜
        del model, trainer
        gc.collect()
        torch.cuda.empty_cache()
    
    # === é˜¶æ®µ 2: è¯„ä¼°æ‰€æœ‰æ£€æŸ¥ç‚¹ ===
    if run_evaluation:
        logger.info("\n==================== [é˜¶æ®µ 2: è¯„ä¼°æ‰€æœ‰æ£€æŸ¥ç‚¹] ====================")
        
        # ä½¿ç”¨ ModelOps æ‰¹é‡è¯„ä¼°
        df_results, best_conf_matrix, test_emotions = ModelOps.evaluate_all_checkpoints(
            model_class=MemoryOptimizedContrastiveModel,
            trainer_class=AblationNoLabelTrainer,
            checkpoint_pattern='Ablation_LGCA_no_Label_model_epoch_*.pt',
            training_dataset_name=training_dataset_name,
            evaluation_dataset_name=evaluation_dataset_name,
            dataloader_func=get_contrastive_dataloaders,
            alpha=alpha
        )
        
        if not df_results.empty:
            # ä¿å­˜ç»“æœåˆ°CSV
            results_path = Path(CONFIG.save_tables_location()) / f"ablation_no_label_evaluation_results_alpha{alpha}.csv"
            df_results.to_csv(results_path, index=False)
            logger.info(f"\nç»“æœå·²ä¿å­˜åˆ°: {results_path}")
            
            # ä¿å­˜æœ€ä½³æ··æ·†çŸ©é˜µ
            if best_conf_matrix is not None:
                best_checkpoint = df_results.iloc[df_results['test_uar'].idxmax()]['checkpoint']
                best_uar = df_results['test_uar'].max()
                
                PlotVisualizer.plot_confusion_matrix(
                    best_conf_matrix,
                    test_emotions,
                    filename=f"ablation_no_label_best_model_cm.png"
                )
                
                logger.info(f"\nğŸ† æœ€ä½³æ¨¡å‹æ£€æŸ¥ç‚¹: {best_checkpoint}")
                logger.info(f"   æœ€ä½³æµ‹è¯•é›† UAR: {best_uar:.2f}%")
                logger.info("   æ··æ·†çŸ©é˜µå·²ä¿å­˜")
        
        logger.info("==================== [é˜¶æ®µ 2: è¯„ä¼°å®Œæˆ] ====================\n")


def run_ablation_no_text(run_training: bool = True, run_evaluation: bool = True, alpha: float = None):
    """
    è¿è¡Œæ¶ˆèå®éªŒ B: LGCA w/o Text Anchor (è®­ç»ƒ + è¯„ä¼°)
    
    Args:
        run_training: æ˜¯å¦è¿è¡Œè®­ç»ƒ
        run_evaluation: æ˜¯å¦è¿è¡Œè¯„ä¼°
        alpha: æŸå¤±æƒé‡ç³»æ•° (å¦‚æœä¸º Noneï¼Œåˆ™ä» config.yaml è¯»å–)
    """
    logger.info("\n" + "="*80)
    logger.info("æ¶ˆèå®éªŒ B: LGCA w/o Text Anchor")
    logger.info("="*80)
    
    # ä» config è·å– alpha å€¼
    if alpha is None:
        alpha = CONFIG.llgca_loss_alpha()
        logger.info(f"ä»é…ç½®æ–‡ä»¶è¯»å– alpha = {alpha}")
    
    training_dataset_name = CONFIG.training_dataset_name()
    evaluation_dataset_name = CONFIG.evaluation_dataset_name()
    num_labels = len(CONFIG.dataset_emotions(training_dataset_name))
    
    # === é˜¶æ®µ 1: è®­ç»ƒ ===
    if run_training:
        logger.info("\n==================== [é˜¶æ®µ 1: å¼€å§‹è®­ç»ƒ] ====================")
        
        # 1. åˆ›å»ºçº¯å£°å­¦æ¨¡å‹ï¼ˆä½¿ç”¨ ModelOpsï¼‰
        model = ModelOps.create_or_load_model(
            model_class=AcousticSupConModel,
            num_labels=num_labels
        )
        
        # 2. åˆ›å»ºè®­ç»ƒå™¨ï¼ˆä½¿ç”¨ ModelOpsï¼‰
        trainer = ModelOps.create_trainer(
            trainer_class=AblationNoTextTrainer,
            model=model,
            alpha=alpha
        )
        
        # 3. è¿è¡Œè®­ç»ƒï¼ˆä½¿ç”¨ ModelOpsï¼‰
        ModelOps.train(
            trainer=trainer,
            training_dataset_name=training_dataset_name,
            dataloader_func=get_ablation_no_text_dataloaders  # æ³¨æ„ï¼šä½¿ç”¨ç‰¹æ®Šçš„æ•°æ®åŠ è½½å™¨
        )
        
        # 4. è®­ç»ƒåç«‹å³åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
        logger.info("--- å¯¹è®­ç»ƒå®Œæˆçš„æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šè¿›è¡Œè¯„ä¼° ---")
        ModelOps.evaluate(
            trainer=trainer,
            dataset_split='validation',
            dataset_name=training_dataset_name,
            dataloader_func=get_ablation_no_text_dataloaders
        )
        
        logger.info("==================== [é˜¶æ®µ 1: è®­ç»ƒå®Œæˆ] ====================\n")
        
        # æ¸…ç†å†…å­˜
        del model, trainer
        gc.collect()
        torch.cuda.empty_cache()
    
    # === é˜¶æ®µ 2: è¯„ä¼°æ‰€æœ‰æ£€æŸ¥ç‚¹ ===
    if run_evaluation:
        logger.info("\n==================== [é˜¶æ®µ 2: è¯„ä¼°æ‰€æœ‰æ£€æŸ¥ç‚¹] ====================")
        
        # ä½¿ç”¨ ModelOps æ‰¹é‡è¯„ä¼°
        df_results, best_conf_matrix, test_emotions = ModelOps.evaluate_all_checkpoints(
            model_class=AcousticSupConModel,
            trainer_class=AblationNoTextTrainer,
            checkpoint_pattern='Ablation_LGCA_no_Text_model_epoch_*.pt',
            training_dataset_name=training_dataset_name,
            evaluation_dataset_name=evaluation_dataset_name,
            dataloader_func=get_ablation_no_text_dataloaders,
            alpha=alpha
        )
        
        if not df_results.empty:
            # ä¿å­˜ç»“æœåˆ°CSV
            results_path = Path(CONFIG.save_tables_location()) / f"ablation_no_text_evaluation_results_alpha{alpha}.csv"
            df_results.to_csv(results_path, index=False)
            logger.info(f"\nç»“æœå·²ä¿å­˜åˆ°: {results_path}")
            
            # ä¿å­˜æœ€ä½³æ··æ·†çŸ©é˜µ
            if best_conf_matrix is not None:
                best_checkpoint = df_results.iloc[df_results['test_uar'].idxmax()]['checkpoint']
                best_uar = df_results['test_uar'].max()
                
                PlotVisualizer.plot_confusion_matrix(
                    best_conf_matrix,
                    test_emotions,
                    filename=f"ablation_no_text_best_model_cm.png"
                )
                
                logger.info(f"\nğŸ† æœ€ä½³æ¨¡å‹æ£€æŸ¥ç‚¹: {best_checkpoint}")
                logger.info(f"   æœ€ä½³æµ‹è¯•é›† UAR: {best_uar:.2f}%")
                logger.info("   æ··æ·†çŸ©é˜µå·²ä¿å­˜")
        
        logger.info("==================== [é˜¶æ®µ 2: è¯„ä¼°å®Œæˆ] ====================\n")


def main():
    """ä¸»å‡½æ•°ï¼šè§£æå‚æ•°å¹¶è¿è¡ŒæŒ‡å®šçš„æ¶ˆèå®éªŒ"""
    parser = argparse.ArgumentParser(description='è¿è¡ŒLGCAæ¶ˆèå®éªŒï¼ˆè®­ç»ƒ+è¯„ä¼°ï¼‰')
    parser.add_argument(
        '--experiment',
        type=str,
        choices=['no_label', 'no_text', 'both'],
        default='both',
        help='è¦è¿è¡Œçš„æ¶ˆèå®éªŒ: no_label (æ— æ ‡ç­¾ç›‘ç£), no_text (æ— æ–‡æœ¬é”šç‚¹), both (ä¸¤è€…éƒ½è¿è¡Œ)'
    )
    parser.add_argument(
        '--alpha',
        type=float,
        default=None,
        help='æŸå¤±æƒé‡ç³»æ•° alpha (å¯é€‰ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä» config.yaml è¯»å–)'
    )
    parser.add_argument(
        '--train-only',
        action='store_true',
        help='åªè¿è¡Œè®­ç»ƒï¼Œä¸è¿è¡Œè¯„ä¼°'
    )
    parser.add_argument(
        '--eval-only',
        action='store_true',
        help='åªè¿è¡Œè¯„ä¼°ï¼Œä¸è¿è¡Œè®­ç»ƒ'
    )
    
    args = parser.parse_args()
    
    # ç¡®å®šè¿è¡Œé˜¶æ®µ
    run_training = not args.eval_only
    run_evaluation = not args.train_only
    
    # å‡†å¤‡ç¯å¢ƒ
    prepare_environment()
    
    # æ ¹æ®å‚æ•°è¿è¡Œå®éªŒ
    if args.experiment in ['no_label', 'both']:
        try:
            run_ablation_no_label(
                run_training=run_training,
                run_evaluation=run_evaluation,
                alpha=args.alpha
            )
        except Exception as e:
            logger.error(f"æ¶ˆèå®éªŒ A (æ— æ ‡ç­¾ç›‘ç£) å¤±è´¥: {e}", exc_info=True)
    
    if args.experiment in ['no_text', 'both']:
        try:
            run_ablation_no_text(
                run_training=run_training,
                run_evaluation=run_evaluation,
                alpha=args.alpha
            )
        except Exception as e:
            logger.error(f"æ¶ˆèå®éªŒ B (æ— æ–‡æœ¬é”šç‚¹) å¤±è´¥: {e}", exc_info=True)
    
    logger.info("\n" + "="*80)
    logger.info("æ‰€æœ‰æ¶ˆèå®éªŒå®Œæˆï¼")
    logger.info("="*80)


if __name__ == "__main__":
    main()
